## **K8's Failure Predictor ğŸš€**  

### **ğŸ“Œ Overview**  
The **AI Failure Predictor** leverages **machine learning** and **Prometheus monitoring** to detect potential system failures in a **Kubernetes cluster** before they happen. This helps in **proactive maintenance** and **reducing downtime**.  

---

## **ğŸ“‚ Project Structure**  

```bash
K8/
â”‚â”€â”€ Dockerfile                 # Docker setup for the application
â”‚â”€â”€ app.py                      # Main API for prediction
â”‚â”€â”€ fetch_metrics.py            # Script to fetch Prometheus metrics
â”‚â”€â”€ k8s-deployment.yaml         # Kubernetes deployment configuration
â”‚â”€â”€ k8s_failure_model.pkl       # Trained ML model
â”‚â”€â”€ patch.json                  # Patch file for Kubernetes service
â”‚â”€â”€ prometheus_data.csv         # Sample Prometheus metrics dataset
â”‚â”€â”€ prometheus_data.json        # Prometheus data in JSON format
â”‚â”€â”€ train_model.py              # Model training script
â”‚â”€â”€ README.md                   # Project documentation
```

---

## **ğŸš€ Installation & Setup**  

### **ğŸ”¹ Prerequisites**  
Ensure you have the following installed:  
- **Docker**  
- **Kubernetes (kubectl, Minikube, or a cluster)**  
- **Python 3.8+**  
- **Prometheus for monitoring**  

### **ğŸ”¹ Clone the Repository**  
```bash
git clone https://github.com/Sonlux/Hthons.git
cd Hthons/K8
```

### **ğŸ”¹ Build & Run Docker Container**  
```bash
docker build -t ai-failure-predictor .
docker run -p 8000:8000 ai-failure-predictor
```

### **ğŸ”¹ Deploy to Kubernetes**  
```bash
kubectl apply -f k8s-deployment.yaml
```

Check the status of the pod:  
```bash
kubectl get pods
```

Expose the service:  
```bash
kubectl expose deployment ai-failure-predictor --type=NodePort --port=8000
```

Find the service URL:  
```bash
minikube service ai-failure-predictor --url
```

---

## **ğŸ–¥ï¸ API Endpoints**  

| Endpoint            | Method | Description |
|---------------------|--------|-------------|
| `/predict`         | `POST` | Sends Prometheus data to predict failures |
| `/metrics`         | `GET`  | Fetches real-time Prometheus metrics |
| `/health`          | `GET`  | Checks if the API is running |

### **ğŸ”¹ Example API Call**  
```bash
curl -X POST http://localhost:8000/predict -H "Content-Type: application/json" -d '{"cpu_usage": 75, "memory_usage": 80, "disk_io": 50}'
```

---

## **ğŸ“Š Monitoring with Prometheus & Grafana**  

1. **Start Prometheus**  
   ```bash
   prometheus --config.file=prometheus.yml
   ```
2. **Access Prometheus Dashboard**  
   ```
   http://localhost:9090
   ```
3. **Visualize Metrics in Grafana**  
   - Add Prometheus as a data source  
   - Create dashboards for monitoring  

---

## **âš™ï¸ Patching the Service (NodePort)**  

If your service isn't accessible, patch it:  
```bash
kubectl patch svc ai-failure-predictor --type="merge" --patch='{"spec": {"type": "NodePort"}}'
```

To check the new port:  
```bash
kubectl get svc ai-failure-predictor
```

---

## **ğŸ¤– Model Training**  

To retrain the ML model:  
```bash
python train_model.py
```

---

## **ğŸ› Troubleshooting**  

| Issue | Solution |
|-------|----------|
| **Service not accessible** | Check if the service is exposed using `kubectl expose` |
| **Pod stuck in `Pending` state** | Run `kubectl describe pod <pod-name>` for details |
| **Docker build issues** | Ensure Docker daemon is running |

---

## **ğŸ”® Future Enhancements**  
âœ… **Multi-cluster support**  
âœ… **Real-time alerting with Prometheus**  
âœ… **More advanced ML models for failure prediction**  

---

## **ğŸ“œ License**  
This project is licensed under the **MIT License**.  

---

